{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Does It Churn, Smeagol?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Client Redacted) approached our company, The Classification Station, to ascertain whether we could build a model to accurately predict whether a customer would \"soon\" stop doing business with (Client Redacted). When a customer withdraws their business, this is known as \"churning\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a certain amount of churn is unavoidable, businesses strive to bring churn to as low a level as possible. In essence, they'd like to keep their customers if they can. So, our company was employed to determined causes of churn and which of those causes had the most impact on (Client Redacted)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This public dataset is provided by the CrowdAnalytix community as part of their churn prediction competition. The real name of the telecom company is anonymized. It contains 20 predictor variables mostly about customer usage patterns. There are 3333 records in this dataset, out of which 483 customers are churners and the remaining 2850 are non-churners. Thus, the ratio of churners in this dataset is 14%. Our first real steps at understanding our data, outside of the metadata we have, is performing a .head(), .describe() and .info() to see some basic statistics about our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, mean_squared_error\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df = pd.read_csv(\"Data/bigml_59c28831336c6604c800002a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account length  area code phone number international plan  \\\n",
       "0    KS             128        415     382-4657                 no   \n",
       "1    OH             107        415     371-7191                 no   \n",
       "2    NJ             137        415     358-1921                 no   \n",
       "3    OH              84        408     375-9999                yes   \n",
       "4    OK              75        415     330-6626                yes   \n",
       "\n",
       "  voice mail plan  number vmail messages  total day minutes  total day calls  \\\n",
       "0             yes                     25              265.1              110   \n",
       "1             yes                     26              161.6              123   \n",
       "2              no                      0              243.4              114   \n",
       "3              no                      0              299.4               71   \n",
       "4              no                      0              166.7              113   \n",
       "\n",
       "   total day charge  ...  total eve calls  total eve charge  \\\n",
       "0             45.07  ...               99             16.78   \n",
       "1             27.47  ...              103             16.62   \n",
       "2             41.38  ...              110             10.30   \n",
       "3             50.90  ...               88              5.26   \n",
       "4             28.34  ...              122             12.61   \n",
       "\n",
       "   total night minutes  total night calls  total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   total intl minutes  total intl calls  total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   customer service calls  churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "3                       2  False  \n",
       "4                       3  False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from a .head(), we have 21 columns ranging from state, account length, account metrics, and a Boolean column to tell us whether the customer has churned or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state                   3333 non-null   object \n",
      " 1   account length          3333 non-null   int64  \n",
      " 2   area code               3333 non-null   int64  \n",
      " 3   phone number            3333 non-null   object \n",
      " 4   international plan      3333 non-null   object \n",
      " 5   voice mail plan         3333 non-null   object \n",
      " 6   number vmail messages   3333 non-null   int64  \n",
      " 7   total day minutes       3333 non-null   float64\n",
      " 8   total day calls         3333 non-null   int64  \n",
      " 9   total day charge        3333 non-null   float64\n",
      " 10  total eve minutes       3333 non-null   float64\n",
      " 11  total eve calls         3333 non-null   int64  \n",
      " 12  total eve charge        3333 non-null   float64\n",
      " 13  total night minutes     3333 non-null   float64\n",
      " 14  total night calls       3333 non-null   int64  \n",
      " 15  total night charge      3333 non-null   float64\n",
      " 16  total intl minutes      3333 non-null   float64\n",
      " 17  total intl calls        3333 non-null   int64  \n",
      " 18  total intl charge       3333 non-null   float64\n",
      " 19  customer service calls  3333 non-null   int64  \n",
      " 20  churn                   3333 non-null   bool   \n",
      "dtypes: bool(1), float64(8), int64(8), object(4)\n",
      "memory usage: 524.2+ KB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little further exploration tells us that there are over 3000 entries, which we knew from our data understanding and the metadata that came along with this dataset. Our data types are object, integer, float (fun integer) and a Boolean column. We also appear to have no nulls in this dataset, which is amazing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                     0\n",
       "account length            0\n",
       "area code                 0\n",
       "phone number              0\n",
       "international plan        0\n",
       "voice mail plan           0\n",
       "number vmail messages     0\n",
       "total day minutes         0\n",
       "total day calls           0\n",
       "total day charge          0\n",
       "total eve minutes         0\n",
       "total eve calls           0\n",
       "total eve charge          0\n",
       "total night minutes       0\n",
       "total night calls         0\n",
       "total night charge        0\n",
       "total intl minutes        0\n",
       "total intl calls          0\n",
       "total intl charge         0\n",
       "customer service calls    0\n",
       "churn                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick verification, we can indeed see that there are no nulls in our dataset, which allows us to use all entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>101.064806</td>\n",
       "      <td>437.182418</td>\n",
       "      <td>8.099010</td>\n",
       "      <td>179.775098</td>\n",
       "      <td>100.435644</td>\n",
       "      <td>30.562307</td>\n",
       "      <td>200.980348</td>\n",
       "      <td>100.114311</td>\n",
       "      <td>17.083540</td>\n",
       "      <td>200.872037</td>\n",
       "      <td>100.107711</td>\n",
       "      <td>9.039325</td>\n",
       "      <td>10.237294</td>\n",
       "      <td>4.479448</td>\n",
       "      <td>2.764581</td>\n",
       "      <td>1.562856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.822106</td>\n",
       "      <td>42.371290</td>\n",
       "      <td>13.688365</td>\n",
       "      <td>54.467389</td>\n",
       "      <td>20.069084</td>\n",
       "      <td>9.259435</td>\n",
       "      <td>50.713844</td>\n",
       "      <td>19.922625</td>\n",
       "      <td>4.310668</td>\n",
       "      <td>50.573847</td>\n",
       "      <td>19.568609</td>\n",
       "      <td>2.275873</td>\n",
       "      <td>2.791840</td>\n",
       "      <td>2.461214</td>\n",
       "      <td>0.753773</td>\n",
       "      <td>1.315491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143.700000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>24.430000</td>\n",
       "      <td>166.600000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>14.160000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.520000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>179.400000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>201.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17.120000</td>\n",
       "      <td>201.200000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.050000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>127.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>216.400000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>36.790000</td>\n",
       "      <td>235.300000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>235.300000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>10.590000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>350.800000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>59.640000</td>\n",
       "      <td>363.700000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>30.910000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>17.770000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       account length    area code  number vmail messages  total day minutes  \\\n",
       "count     3333.000000  3333.000000            3333.000000        3333.000000   \n",
       "mean       101.064806   437.182418               8.099010         179.775098   \n",
       "std         39.822106    42.371290              13.688365          54.467389   \n",
       "min          1.000000   408.000000               0.000000           0.000000   \n",
       "25%         74.000000   408.000000               0.000000         143.700000   \n",
       "50%        101.000000   415.000000               0.000000         179.400000   \n",
       "75%        127.000000   510.000000              20.000000         216.400000   \n",
       "max        243.000000   510.000000              51.000000         350.800000   \n",
       "\n",
       "       total day calls  total day charge  total eve minutes  total eve calls  \\\n",
       "count      3333.000000       3333.000000        3333.000000      3333.000000   \n",
       "mean        100.435644         30.562307         200.980348       100.114311   \n",
       "std          20.069084          9.259435          50.713844        19.922625   \n",
       "min           0.000000          0.000000           0.000000         0.000000   \n",
       "25%          87.000000         24.430000         166.600000        87.000000   \n",
       "50%         101.000000         30.500000         201.400000       100.000000   \n",
       "75%         114.000000         36.790000         235.300000       114.000000   \n",
       "max         165.000000         59.640000         363.700000       170.000000   \n",
       "\n",
       "       total eve charge  total night minutes  total night calls  \\\n",
       "count       3333.000000          3333.000000        3333.000000   \n",
       "mean          17.083540           200.872037         100.107711   \n",
       "std            4.310668            50.573847          19.568609   \n",
       "min            0.000000            23.200000          33.000000   \n",
       "25%           14.160000           167.000000          87.000000   \n",
       "50%           17.120000           201.200000         100.000000   \n",
       "75%           20.000000           235.300000         113.000000   \n",
       "max           30.910000           395.000000         175.000000   \n",
       "\n",
       "       total night charge  total intl minutes  total intl calls  \\\n",
       "count         3333.000000         3333.000000       3333.000000   \n",
       "mean             9.039325           10.237294          4.479448   \n",
       "std              2.275873            2.791840          2.461214   \n",
       "min              1.040000            0.000000          0.000000   \n",
       "25%              7.520000            8.500000          3.000000   \n",
       "50%              9.050000           10.300000          4.000000   \n",
       "75%             10.590000           12.100000          6.000000   \n",
       "max             17.770000           20.000000         20.000000   \n",
       "\n",
       "       total intl charge  customer service calls  \n",
       "count        3333.000000             3333.000000  \n",
       "mean            2.764581                1.562856  \n",
       "std             0.753773                1.315491  \n",
       "min             0.000000                0.000000  \n",
       "25%             2.300000                1.000000  \n",
       "50%             2.780000                1.000000  \n",
       "75%             3.270000                2.000000  \n",
       "max             5.400000                9.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A final \"first step\" in our exploration process is to see some simple statistics for our dataset. In this case, these aren't particularly relevant; I highly doubt that a customer's minutes used impacted their churn, but we have the data nonetheless, and it can allow us to account for outliers and better understand our data overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we've begun to grasp the contents and use of our data, we can begin to decide what is and is not useful. We can also begin to think about which type of model might be best for the problem we've been presented, and begin to curate our data for that purpose. Our first real step is to decide which columns will or will not be useful to our purposes, and drop those that are unncecessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 21 available columns, and they are listed here, for a quick refresher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state                   3333 non-null   object \n",
      " 1   account length          3333 non-null   int64  \n",
      " 2   area code               3333 non-null   int64  \n",
      " 3   phone number            3333 non-null   object \n",
      " 4   international plan      3333 non-null   object \n",
      " 5   voice mail plan         3333 non-null   object \n",
      " 6   number vmail messages   3333 non-null   int64  \n",
      " 7   total day minutes       3333 non-null   float64\n",
      " 8   total day calls         3333 non-null   int64  \n",
      " 9   total day charge        3333 non-null   float64\n",
      " 10  total eve minutes       3333 non-null   float64\n",
      " 11  total eve calls         3333 non-null   int64  \n",
      " 12  total eve charge        3333 non-null   float64\n",
      " 13  total night minutes     3333 non-null   float64\n",
      " 14  total night calls       3333 non-null   int64  \n",
      " 15  total night charge      3333 non-null   float64\n",
      " 16  total intl minutes      3333 non-null   float64\n",
      " 17  total intl calls        3333 non-null   int64  \n",
      " 18  total intl charge       3333 non-null   float64\n",
      " 19  customer service calls  3333 non-null   int64  \n",
      " 20  churn                   3333 non-null   bool   \n",
      "dtypes: bool(1), float64(8), int64(8), object(4)\n",
      "memory usage: 524.2+ KB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the available options, there are some that are simply not useful for our purpose as they are unlikely to have any correlation to churn. Unnecessary columns (to my thinking) include \"area code\", \"phone number\", \"voice mail plan\", \"number vmail messages\", \"total day minutes\", \"total day charge\", \"total eve minutes\", \"total eve charge\", \"total night minutes\", \"total night charge\", \"total intl minutes\" and \"total intl charge\". I find these things to have no relation on customer churn and so these columns will be dropped before we proceed to split our data for testing and training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cust_df = cust_df.drop([\"area code\", \"phone number\", \"voice mail plan\", \"number vmail messages\", \"total day minutes\", \"total day charge\", \"total eve minutes\", \"total eve charge\", \"total night minutes\", \"total night charge\", \"total intl minutes\", \"total intl charge\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   state                   3333 non-null   object\n",
      " 1   account length          3333 non-null   int64 \n",
      " 2   international plan      3333 non-null   object\n",
      " 3   total day calls         3333 non-null   int64 \n",
      " 4   total eve calls         3333 non-null   int64 \n",
      " 5   total night calls       3333 non-null   int64 \n",
      " 6   total intl calls        3333 non-null   int64 \n",
      " 7   customer service calls  3333 non-null   int64 \n",
      " 8   churn                   3333 non-null   bool  \n",
      "dtypes: bool(1), int64(6), object(2)\n",
      "memory usage: 211.7+ KB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, remaining we have \"state\", \"account length\", \"international plan\", \"total day/eve/night/itl calls\", \"customer service calls\" and \"churn\". These seem important because the state someone lives in may impact their service and thus their decision to churn. Their account length may also have an impact, as well as whether or not their plan works (or is required to work) internationally. The amount of usage, as seen in the total calls metrics, can have an impact on churn; perhaps the customer simply isn't using the service enough to warrant keeping it. Finally, customer service calls may indicate that the service is not working well, and that itself may lead to churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step before any further transformations or analysis is to separate our data into a \"testing\" and a \"training\" set. This means that as we build our model, it will only have access to the training data, and during evaluation, it will have access to the testing data. Never the twain shall meet, or it will result in data leakage, which is to be avoided at all costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cust_df.drop('churn', axis=1)\n",
    "y = cust_df['churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bit of code above has performed the train/test split as described, with a test size of .25 meaning that .75 of the data will be used for training the model, and .25 will be used for testing it. We've also set a random state of 42, an arbitrary number that guarantees randomization of our data during splitting, guaranteeing that the result will be representative of aforementioned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now has come the time to analyze our data, though we still have some preprocessing steps. We can wrap all of that up into a pipeline! Our created pipeline will have many uses. First, it will use a method called SMOTE to help deal with the class imbalance we have. It is not recommended to undersample the majority, as that is simply leaving data on the table, and so we will be oversampling the minority. In this case, we will be \"making up for\" the 14% of churned customers in this dataset so that our model can function. Secondly, our pipeline will be using StandardScaler() to scale our numeric columns so that they are \"weighted\" the same, so to speak. There will be far fewer \"customer service calls\" than \"total day calls\", for example, but the two factors are considered equally important, and so the numerics will be scaled. Third, our pipeline will use OneHotEncoder() to transform \"state\" and \"international plan\" into Boolean values similar to \"churn\" and thus allow us to further model these fatures versus our target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target, \"churn\" is already a Boolean value and thus does not need to be encoded; it would be redundant. In any case, once our pipeline is properly set up and implemented, we will also have a logistic regression model, and we can proceed with tuning that model and deciding whether a logistic regression is the best type of model for this question. We will also be exploring a decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['account length',\n",
       "                                                   'total day calls',\n",
       "                                                   'total eve calls',\n",
       "                                                   'total night calls',\n",
       "                                                   'total intl calls',\n",
       "                                                   'customer service calls']),\n",
       "                                                 ('cat', OneHotEncoder(),\n",
       "                                                  ['state',\n",
       "                                                   'international plan'])])),\n",
       "                ('sampler', SMOTE()), ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = ['account length', 'total day calls', 'total eve calls', 'total night calls', 'total intl calls', 'customer service calls']\n",
    "categorical_features = ['state', 'international plan']\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "steps = [\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('sampler', SMOTE()),\n",
    "    ('classifier', LogisticRegression())\n",
    "]\n",
    "\n",
    "log_pipeline = Pipeline(steps)\n",
    "\n",
    "log_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a logistic regression model that has been fitted to our training data. Yay! There are four important \"metrics\" that we care about in terms of a logistic regression model. Those metrics are accuracy, precision, recall, and an F1 score. Each has their own definition and reason for importance depending on context, but the one we care most about in this context is the accuracy score, and potentially the precision score. These two scores are defined as follows -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is the proportion of correctly defined labels. Or, how many did our model get correct? Considering we were asked to build and tune a model to accurately predict whether a customer would soon churn, that's a very important metric! We also might care about the precision score, which is the proportion of true positive predictions out of all positive predictions. This metric may matter because our model is attempting to accurately predict that something will happen, or a positive result. Therefore, we care about how well it predicts that positive result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can be looked at very easily, as seen here -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_acc = log_pipeline.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7342937174869948"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our logistic regression model has a 73% accuracy rate, meaning that 73% of the time, it labeled a customer accurately. Not especially good, but also not terrible. Now let's check out the precision score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we created our pipeline, we fit the training data to our pipeline object, using it as a logistic regression model, which it created. Now, we need to make predictions based on that training data to obtain our precision score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pre = precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2788104089219331"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our precision score is awful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
